{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mingxu/miniconda3/envs/ML/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load CIFAR-100 dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import transforms\n",
    "# import neccessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import logging.handlers\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import torch.nn.parallel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_ori = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_ori)\n",
    "\n",
    "# 首先获取类别信息\n",
    "classes = test_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128 load dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  10000\n",
      "Total Batch:  79\n"
     ]
    }
   ],
   "source": [
    "print('Test: ', len(test_loader.dataset))\n",
    "print('Total Batch: ', len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmingxu_zhang\u001b[0m (\u001b[33mmingxus-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/mingxu/DL/Final_work/Deep-Learning/mingxu/wandb/run-20240526_133043-vku98fbb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mingxus-team/DL_Classification_CIFAR-100/runs/vku98fbb' target=\"_blank\">classic-snowball-64</a></strong> to <a href='https://wandb.ai/mingxus-team/DL_Classification_CIFAR-100' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mingxus-team/DL_Classification_CIFAR-100' target=\"_blank\">https://wandb.ai/mingxus-team/DL_Classification_CIFAR-100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mingxus-team/DL_Classification_CIFAR-100/runs/vku98fbb' target=\"_blank\">https://wandb.ai/mingxus-team/DL_Classification_CIFAR-100/runs/vku98fbb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mingxus-team/DL_Classification_CIFAR-100/runs/vku98fbb?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8a6af7d180>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "wandb.init(\n",
    "    project=\"DL_Classification_CIFAR-100\",\n",
    "    config={\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"architecture\": \"Model_Essemble_Resnet\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 50,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100, dropout_rate=0.5):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 32\n",
    "        self.conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self.make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self.make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn(self.conv(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out) \n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "    def evaluate(self, test_loader, criterion, use_cuda, index):\n",
    "        # calculate the accuracy on the test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        class_correct = list(0. for i in range(100))\n",
    "        class_total = list(0. for i in range(100))\n",
    "        for data, target in tqdm(test_loader):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()*data.size(0)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            correct = np.squeeze(correct_tensor.numpy()) if not use_cuda else np.squeeze(correct_tensor.cpu().numpy())\n",
    "            for i in range(len(target.data)):\n",
    "                label = target.data[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "        test_loss = test_loss/len(test_loader.dataset)\n",
    "        for i in range(100):\n",
    "            if class_total[i] > 0:\n",
    "                # log accuracy of each class\n",
    "                # wandb.log({\"acc_{}\".format(classes[i]): class_correct[i] / class_total[i]})\n",
    "                wandb.log({\"acc_model_{}\".format(index): class_correct[i] / class_total[i]})\n",
    "                #print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (str(i), 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "            else:\n",
    "                print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))  \n",
    "        #wandb log the average acc\n",
    "        # wandb.log({\"acc\": np.sum(class_correct) / np.sum(class_total)})\n",
    "        # print average acc\n",
    "        print('Test Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))\n",
    "        \n",
    "\n",
    "    def train_model(model, train_loader, valid_loader, epochs, optimizer, criterion, use_cuda, save_path):\n",
    "        valid_loss_min = np.Inf\n",
    "        count = 0\n",
    "        for epoch in range(1, epochs+1):\n",
    "            train_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            model.train()\n",
    "            for data, target in tqdm(train_loader):\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()*data.size(0)\n",
    "            model.eval()\n",
    "            for data, target in valid_loader:\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += loss.item()*data.size(0)\n",
    "            train_loss = train_loss/len(train_loader.sampler)\n",
    "            valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "            model.evaluate( valid_loader, criterion, use_cuda)\n",
    "            wandb.log({\"training_loss\": train_loss, \"val_loss\": valid_loss})  \n",
    "\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                valid_loss_min = valid_loss\n",
    "                count = 0\n",
    "            else :\n",
    "                count = count + 1\n",
    "                if count > 10:\n",
    "                    break\n",
    "            torch.save(model.state_dict(), save_path + str(epoch%5))\n",
    "\n",
    "    def predict(model, test_loader, use_cuda):\n",
    "        model.eval()  # Ensure the model is in evaluation mode\n",
    "        predictions = []\n",
    "        with torch.no_grad():  # Turn off gradients for validation, saves memory and computations\n",
    "            for data, _ in tqdm(test_loader):\n",
    "                if use_cuda:\n",
    "                    data = data.cuda()  # Move data to GPU if CUDA is enabled\n",
    "                output = model(data)\n",
    "                _, pred = torch.max(output, 1)  # Get the index of the max log-probability\n",
    "                pred = pred.cpu().numpy() if use_cuda else pred.numpy()  # Move data to CPU if CUDA is used\n",
    "                predictions.extend(pred)\n",
    "        return predictions\n",
    "\n",
    "    def predict_poss(model, test_loader, use_cuda):\n",
    "        model.eval()  # Ensure the model is in evaluation mode\n",
    "        probabilities = []\n",
    "        with torch.no_grad():  # Turn off gradients for validation, saves memory and computations\n",
    "            for data, _ in tqdm(test_loader):\n",
    "                if use_cuda:\n",
    "                    data = data.cuda()  # Move data to GPU if CUDA is enabled\n",
    "\n",
    "                output = model(data)\n",
    "                prob = F.softmax(output, dim=1)  # Compute the probability distribution over classes\n",
    "\n",
    "                if use_cuda:\n",
    "                    prob = prob.cpu()  # Move data to CPU if CUDA is used\n",
    "\n",
    "                probabilities.append(prob.numpy())  # Store the probabilities\n",
    "\n",
    "        # 使用 np.vstack 以确保即使批量大小不同也能正确合并\n",
    "        return np.vstack(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model0 = ResNet(ResidualBlock, [5, 6, 7, 8])\n",
    "model1 = ResNet(ResidualBlock, [5, 6, 7, 8])\n",
    "model2 = ResNet(ResidualBlock, [5, 6, 7, 8])\n",
    "model3 = ResNet(ResidualBlock, [5, 6, 7, 8])\n",
    "model4 = ResNet(ResidualBlock, [5, 6, 7, 8])\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model0 = model0.cuda()\n",
    "    model1 = model1.cuda()\n",
    "    model2 = model2.cuda()\n",
    "    model3 = model3.cuda()\n",
    "    model4 = model4.cuda()\n",
    "\n",
    "# load model\n",
    "model0.load_state_dict(torch.load('ResNet_baseline_model_enhance0.pt'))\n",
    "model1.load_state_dict(torch.load('ResNet_baseline_model_enhance1.pt'))\n",
    "model2.load_state_dict(torch.load('ResNet_baseline_model_enhance2.pt'))\n",
    "model3.load_state_dict(torch.load('ResNet_baseline_model_enhance3.pt'))\n",
    "model4.load_state_dict(torch.load('ResNet_baseline_model_enhance4.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:04<00:00, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Overall): 48% (4899/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(ResidualBlock, [5, 6, 7, 8])\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "# train model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.load_state_dict(torch.load('ResNet_baseline_model.pt'))\n",
    "model.evaluate(test_loader, criterion, use_cuda, 'ResNet_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel0.eval()\\nmodel1.eval()\\nmodel2.eval()\\nmodel3.eval()\\nmodel4.eval()\\n\\ntest_preds0 = torch.tensor(model0.predict(test_loader, use_cuda), dtype=torch.long)\\ntest_preds1 = torch.tensor(model1.predict(test_loader, use_cuda), dtype=torch.long)\\ntest_preds2 = torch.tensor(model2.predict(test_loader, use_cuda), dtype=torch.long)\\ntest_preds3 = torch.tensor(model3.predict(test_loader, use_cuda), dtype=torch.long)\\ntest_preds4 = torch.tensor(model4.predict(test_loader, use_cuda), dtype=torch.long)\\n\\nstacked_preds = torch.stack([test_preds0, test_preds1, test_preds2, test_preds3, test_preds4], dim=0)\\n\\n# Apply torch.mode to find the most common prediction along the stacked dimension\\ntest_preds = torch.mode(stacked_preds, dim=0).values\\n\\n# Ensure that the dataset has an attribute \\'targets\\' or adjust according to your dataset structure\\nclass_correct = list(0. for i in range(100))\\nclass_total = list(0. for i in range(100))\\nfor i in range(len(test_loader.dataset.targets)):\\n    label = test_loader.dataset.targets[i]\\n    class_correct[label] += int(test_preds[i].item() == label)\\n\\n    class_total[label] += 1\\n\\n# Log ensemble accuracies to wandb and print them\\nfor i in range(100):\\n    if class_total[i] > 0:\\n        wandb.log({\"acc_ensemble_voting5\": class_correct[i] / class_total[i]})\\n        print(\\'Test Accuracy of %5s: %2d%% (%2d/%2d)\\' % (str(i), 100 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\\n    else:\\n        print(\\'Test Accuracy of %5s: N/A (no training examples)\\' % i)\\n\\n# Calculate and print overall accuracy\\nprint(\\'Test Accuracy (Overall): %2d%% (%2d/%2d)\\' % (100. * sum(class_correct) / sum(class_total), sum(class_correct), sum(class_total)))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用多数投票的方式进行集成\n",
    "'''\n",
    "model0.eval()\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "\n",
    "test_preds0 = torch.tensor(model0.predict(test_loader, use_cuda), dtype=torch.long)\n",
    "test_preds1 = torch.tensor(model1.predict(test_loader, use_cuda), dtype=torch.long)\n",
    "test_preds2 = torch.tensor(model2.predict(test_loader, use_cuda), dtype=torch.long)\n",
    "test_preds3 = torch.tensor(model3.predict(test_loader, use_cuda), dtype=torch.long)\n",
    "test_preds4 = torch.tensor(model4.predict(test_loader, use_cuda), dtype=torch.long)\n",
    "\n",
    "stacked_preds = torch.stack([test_preds0, test_preds1, test_preds2, test_preds3, test_preds4], dim=0)\n",
    "\n",
    "# Apply torch.mode to find the most common prediction along the stacked dimension\n",
    "test_preds = torch.mode(stacked_preds, dim=0).values\n",
    "\n",
    "# Ensure that the dataset has an attribute 'targets' or adjust according to your dataset structure\n",
    "class_correct = list(0. for i in range(100))\n",
    "class_total = list(0. for i in range(100))\n",
    "for i in range(len(test_loader.dataset.targets)):\n",
    "    label = test_loader.dataset.targets[i]\n",
    "    class_correct[label] += int(test_preds[i].item() == label)\n",
    "\n",
    "    class_total[label] += 1\n",
    "\n",
    "# Log ensemble accuracies to wandb and print them\n",
    "for i in range(100):\n",
    "    if class_total[i] > 0:\n",
    "        wandb.log({\"acc_ensemble_voting5\": class_correct[i] / class_total[i]})\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (str(i), 100 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % i)\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "print('Test Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * sum(class_correct) / sum(class_total), sum(class_correct), sum(class_total)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 确保模型在评估模式\\nmodel0.eval()\\nmodel1.eval()\\nmodel2.eval()\\nmodel3.eval()\\nmodel4.eval()\\n\\n# 获取每个模型的概率预测\\nprob_preds0 = np.array(model0.predict_poss(test_loader, use_cuda))\\nprob_preds1 = np.array(model1.predict_poss(test_loader, use_cuda))\\nprob_preds2 = np.array(model2.predict_poss(test_loader, use_cuda))\\nprob_preds3 = np.array(model3.predict_poss(test_loader, use_cuda))\\nprob_preds4 = np.array(model4.predict_poss(test_loader, use_cuda))\\n\\n# 将所有模型的概率相加\\nsummed_probs = prob_preds0 + prob_preds1 + prob_preds2 + prob_preds3 + prob_preds4\\n\\n# 选择概率总和最大的类别作为最终预测\\ntest_preds = np.argmax(summed_probs, axis=1)\\n\\n# 确保数据集具有属性 \\'targets\\' 或根据您的数据集结构进行调整\\nclass_correct = list(0. for i in range(100))\\nclass_total = list(0. for i in range(100))\\nfor i, label in enumerate(test_loader.dataset.targets):\\n    class_correct[label] += int(test_preds[i] == label)\\n    class_total[label] += 1\\n\\n# 打印每个类别的精度\\nfor i in range(100):\\n    if class_total[i] > 0:\\n        wandb.log({\"acc_ensemble_possibility\": class_correct[i] / class_total[i]})\\n        print(\\'Test Accuracy of %5s: %2d%% (%2d/%2d)\\' % (str(i), 100 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\\n    else:\\n        print(\\'Test Accuracy of %5s: N/A (no training examples)\\' % i)\\n\\n# 计算并打印总体精度\\noverall_accuracy = 100. * sum(class_correct) / sum(class_total)\\nprint(\\'Test Accuracy (Overall): %2d%% (%2d/%2d)\\' % (100. * sum(class_correct) / sum(class_total), sum(class_correct), sum(class_total)))\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "'''\n",
    "# 确保模型在评估模式\n",
    "model0.eval()\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "\n",
    "# 获取每个模型的概率预测\n",
    "prob_preds0 = np.array(model0.predict_poss(test_loader, use_cuda))\n",
    "prob_preds1 = np.array(model1.predict_poss(test_loader, use_cuda))\n",
    "prob_preds2 = np.array(model2.predict_poss(test_loader, use_cuda))\n",
    "prob_preds3 = np.array(model3.predict_poss(test_loader, use_cuda))\n",
    "prob_preds4 = np.array(model4.predict_poss(test_loader, use_cuda))\n",
    "\n",
    "# 将所有模型的概率相加\n",
    "summed_probs = prob_preds0 + prob_preds1 + prob_preds2 + prob_preds3 + prob_preds4\n",
    "\n",
    "# 选择概率总和最大的类别作为最终预测\n",
    "test_preds = np.argmax(summed_probs, axis=1)\n",
    "\n",
    "# 确保数据集具有属性 'targets' 或根据您的数据集结构进行调整\n",
    "class_correct = list(0. for i in range(100))\n",
    "class_total = list(0. for i in range(100))\n",
    "for i, label in enumerate(test_loader.dataset.targets):\n",
    "    class_correct[label] += int(test_preds[i] == label)\n",
    "    class_total[label] += 1\n",
    "\n",
    "# 打印每个类别的精度\n",
    "for i in range(100):\n",
    "    if class_total[i] > 0:\n",
    "        wandb.log({\"acc_ensemble_possibility\": class_correct[i] / class_total[i]})\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (str(i), 100 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % i)\n",
    "\n",
    "# 计算并打印总体精度\n",
    "overall_accuracy = 100. * sum(class_correct) / sum(class_total)\n",
    "print('Test Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * sum(class_correct) / sum(class_total), sum(class_correct), sum(class_total)))\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
